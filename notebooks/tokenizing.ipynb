{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=TIKVAH.txt --model_prefix=mt --vocab_size=2000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: TIKVAH.txt\n",
      "  input_format: \n",
      "  model_prefix: mt\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 2000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: TIKVAH.txt\n",
      "trainer_interface.cc(378) LOG(WARNING) Found too long line (5737 > 4192).\n",
      "trainer_interface.cc(380) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(381) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 16433 sentences\n",
      "trainer_interface.cc(414) LOG(INFO) Skipped 275 too long sentences.\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=4897676\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9503% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=298\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999503\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 16433 sentences.\n",
      "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=2198202\n",
      "unigram_model_trainer.cc(274) LOG(INFO) Initialized 158353 seed sentencepieces\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 16433\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 135175\n",
      "unigram_model_trainer.cc(564) LOG(INFO) Using 135175 sentences for EM training\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=75748 obj=13.0676 num_tokens=270036 num_tokens/piece=3.56493\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=66392 obj=11.5167 num_tokens=271825 num_tokens/piece=4.09424\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=49766 obj=11.5326 num_tokens=289026 num_tokens/piece=5.8077\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=49719 obj=11.4941 num_tokens=289114 num_tokens/piece=5.81496\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=37289 obj=11.6551 num_tokens=311892 num_tokens/piece=8.36418\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=37285 obj=11.6114 num_tokens=311959 num_tokens/piece=8.36688\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=27963 obj=11.836 num_tokens=336675 num_tokens/piece=12.04\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=27963 obj=11.782 num_tokens=336709 num_tokens/piece=12.0412\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=20972 obj=12.0624 num_tokens=362050 num_tokens/piece=17.2635\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=20972 obj=12.0004 num_tokens=362061 num_tokens/piece=17.264\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=15729 obj=12.3357 num_tokens=387804 num_tokens/piece=24.6553\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=15729 obj=12.264 num_tokens=387825 num_tokens/piece=24.6567\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=11796 obj=12.6664 num_tokens=414411 num_tokens/piece=35.1315\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=11796 obj=12.5802 num_tokens=414520 num_tokens/piece=35.1407\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=8847 obj=13.027 num_tokens=440171 num_tokens/piece=49.7537\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=8847 obj=12.935 num_tokens=440175 num_tokens/piece=49.7542\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=6635 obj=13.43 num_tokens=466090 num_tokens/piece=70.2472\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=6635 obj=13.3266 num_tokens=466338 num_tokens/piece=70.2846\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=4976 obj=13.8758 num_tokens=493170 num_tokens/piece=99.1097\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=4976 obj=13.7585 num_tokens=493810 num_tokens/piece=99.2383\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=3732 obj=14.3751 num_tokens=520309 num_tokens/piece=139.418\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=3732 obj=14.2457 num_tokens=520312 num_tokens/piece=139.419\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=2799 obj=14.9114 num_tokens=547282 num_tokens/piece=195.528\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=2799 obj=14.775 num_tokens=547891 num_tokens/piece=195.745\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=2200 obj=15.373 num_tokens=570962 num_tokens/piece=259.528\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=2200 obj=15.2486 num_tokens=570964 num_tokens/piece=259.529\n",
      "trainer_interface.cc(686) LOG(INFO) Saving model: mt.model\n",
      "trainer_interface.cc(698) LOG(INFO) Saving vocabs: mt.vocab\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "# train sentencepiece model from `TIKVAH.txt` and makes `m.model` and `m.vocab`\n",
    "# `m.vocab` is just a reference. not used in the segmentation.\n",
    "spm.SentencePieceTrainer.train('--input=TIKVAH.txt --model_prefix=mt --vocab_size=2000')\n",
    "\n",
    "# makes segmenter instance and loads the model file (m.model)\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('m.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assuming `sp` is your SentencePieceProcessor instance loaded with 'm.model'\n",
    "with open('labled.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "tokens = sp.encode_as_pieces(text)  # or sp.encode_as_ids(text) for numerical ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁በኢትዮጵያ',\n",
       " '▁4',\n",
       " '30',\n",
       " '▁ሺህ',\n",
       " '▁ዜጎች',\n",
       " '▁የ',\n",
       " 'ኮቪድ',\n",
       " '▁19',\n",
       " '▁ክትባት',\n",
       " '▁መ',\n",
       " 'ከተ',\n",
       " 'ባቸው',\n",
       " '▁የጤና',\n",
       " '▁ሚኒስቴር',\n",
       " '▁ገለፀ',\n",
       " '!',\n",
       " '▁በኢትዮጵያ',\n",
       " '▁እስከ',\n",
       " '▁አሁን',\n",
       " '▁4',\n",
       " '30',\n",
       " '▁ሺህ',\n",
       " '▁ዜጎች',\n",
       " '▁የ',\n",
       " 'ኮቪድ',\n",
       " '▁19',\n",
       " '▁ክትባት',\n",
       " '▁መ',\n",
       " 'ከተ',\n",
       " 'ባቸው',\n",
       " 'ን',\n",
       " '▁የጤና',\n",
       " '▁ሚኒስቴር',\n",
       " '▁ገልጿል፡፡',\n",
       " 'በ',\n",
       " 'ክ',\n",
       " 'ት',\n",
       " 'ባ',\n",
       " 'ቱ',\n",
       " '▁የ',\n",
       " 'ጎ',\n",
       " 'ላ',\n",
       " '▁የ',\n",
       " 'ጎ',\n",
       " 'ን',\n",
       " 'ዮ',\n",
       " 'ሽ',\n",
       " '▁ጉዳት',\n",
       " '▁እንዳል',\n",
       " 'ታ',\n",
       " 'የ',\n",
       " '▁የጤና',\n",
       " '▁ሚኒስትር',\n",
       " '▁ዶ',\n",
       " '/',\n",
       " 'ር',\n",
       " '▁ሊያ',\n",
       " '▁ታደሰ',\n",
       " '▁ዛሬ',\n",
       " '▁በሰጡት',\n",
       " '▁መግለጫ',\n",
       " '▁ተናግረዋል፡፡',\n",
       " '▁Via',\n",
       " '▁',\n",
       " 'EBC',\n",
       " '▁ጠቅላይ',\n",
       " '▁ሚኒስትር',\n",
       " '▁አቢይ',\n",
       " '▁አሕመድ',\n",
       " '▁እና',\n",
       " '▁',\n",
       " 'ልኡካን',\n",
       " '▁',\n",
       " 'ቡ',\n",
       " 'ድ',\n",
       " 'ና',\n",
       " 'ቸው',\n",
       " '▁ለ',\n",
       " 'ሥራ',\n",
       " '▁ጉብኝት',\n",
       " '▁',\n",
       " 'ቱ',\n",
       " 'ር',\n",
       " 'ክ',\n",
       " '፣',\n",
       " '▁አ',\n",
       " 'ን',\n",
       " 'ካ',\n",
       " 'ራ',\n",
       " '▁ተ',\n",
       " 'ገኝ',\n",
       " 'ተዋል።',\n",
       " '▁ጠቅላይ',\n",
       " '▁ሚኒስትር',\n",
       " '▁አቢይ',\n",
       " '▁አሕመድ',\n",
       " '▁በ',\n",
       " 'ቆይ',\n",
       " 'ታቸው',\n",
       " '▁',\n",
       " 'ፕሬ',\n",
       " 'ዚ',\n",
       " 'ደ',\n",
       " 'ን',\n",
       " 'ት',\n",
       " '▁',\n",
       " 'ረ',\n",
       " 'ሲ',\n",
       " 'ፕ',\n",
       " '▁ታ',\n",
       " 'ይ',\n",
       " 'ፕ',\n",
       " '▁ኤ',\n",
       " 'ር',\n",
       " 'ዶ',\n",
       " 'ጋ',\n",
       " 'ን',\n",
       " 'ን',\n",
       " '▁አ',\n",
       " 'ግ',\n",
       " 'ኝ',\n",
       " 'ተው',\n",
       " '▁በሁለት',\n",
       " 'ዮ',\n",
       " 'ሽ',\n",
       " '▁እና',\n",
       " '▁',\n",
       " 'ቀጣ',\n",
       " 'ና',\n",
       " 'ዊ',\n",
       " '▁የጋራ',\n",
       " '▁የ',\n",
       " 'ት',\n",
       " 'ኩ',\n",
       " 'ረ',\n",
       " 'ት',\n",
       " '▁በ',\n",
       " 'ሆኑ',\n",
       " '▁ጉዳዮች',\n",
       " '▁ላይ',\n",
       " '▁እንደሚ',\n",
       " 'ወያዩ',\n",
       " '▁ከ',\n",
       " 'ጠቅላይ',\n",
       " '▁ሚኒስትር',\n",
       " '▁ፅ',\n",
       " '/',\n",
       " 'ቤት',\n",
       " '▁ያገኘነው',\n",
       " '▁መረጃ',\n",
       " '▁ያ',\n",
       " 'ሳ',\n",
       " 'ያ',\n",
       " 'ል።',\n",
       " '▁አቶ',\n",
       " '▁ሽ',\n",
       " 'መ',\n",
       " 'ል',\n",
       " 'ስ',\n",
       " '▁አብ',\n",
       " 'ዲ',\n",
       " 'ሳ',\n",
       " '▁የኦሮሚያ',\n",
       " '▁ክልል',\n",
       " '▁ፕሬዚዳንት',\n",
       " '▁ሆነው',\n",
       " '▁ተ',\n",
       " 'መረ',\n",
       " 'ጡ',\n",
       " '!',\n",
       " '▁የ',\n",
       " 'ጨ',\n",
       " 'ፌ',\n",
       " '▁',\n",
       " 'ኦሮሚያ',\n",
       " '▁ምክር',\n",
       " '▁ቤት',\n",
       " '▁አቶ',\n",
       " '▁ሽ',\n",
       " 'መ',\n",
       " 'ል',\n",
       " 'ስ',\n",
       " '▁አብ',\n",
       " 'ዲ',\n",
       " 'ሳ',\n",
       " 'ን',\n",
       " '▁የኦሮሚያ',\n",
       " '▁ክልል',\n",
       " '▁ፕሬዚዳንት',\n",
       " '▁አድርጎ',\n",
       " '▁',\n",
       " 'ሾ',\n",
       " 'መ',\n",
       " '።',\n",
       " 'አቶ',\n",
       " '▁ሽ',\n",
       " 'መ',\n",
       " 'ል',\n",
       " 'ስ',\n",
       " '▁የክልል',\n",
       " '▁ፕሬዚዳንት',\n",
       " '▁ሆነው',\n",
       " '▁የተ',\n",
       " 'መረ',\n",
       " 'ጡ',\n",
       " 'ት',\n",
       " '▁ዛሬ',\n",
       " '▁ስራ',\n",
       " '▁በ',\n",
       " 'ጀመረ',\n",
       " 'ው',\n",
       " '▁በ',\n",
       " 'አዲሱ',\n",
       " '▁የ',\n",
       " 'ጨ',\n",
       " 'ፌ',\n",
       " '▁አባላት',\n",
       " '▁ነው፡፡',\n",
       " 'ፕሬ',\n",
       " 'ዚ',\n",
       " 'ዳ',\n",
       " 'ን',\n",
       " 'ቱ',\n",
       " '▁በ',\n",
       " 'ም',\n",
       " 'ክር',\n",
       " '▁ቤቱ',\n",
       " '▁',\n",
       " 'ፊ',\n",
       " 'ት',\n",
       " '▁ቀር',\n",
       " 'በ',\n",
       " 'ው',\n",
       " '▁',\n",
       " 'ቃ',\n",
       " 'ለ',\n",
       " '▁መ',\n",
       " 'ሃ',\n",
       " 'ላ',\n",
       " '▁ፈ',\n",
       " 'ፅ',\n",
       " 'መ',\n",
       " 'ዋል፡፡',\n",
       " '▁የአዲስ',\n",
       " '▁አበባ',\n",
       " '▁ከተማ',\n",
       " '▁ከንቲባ',\n",
       " '▁አዳነች',\n",
       " '▁አ',\n",
       " 'ቤ',\n",
       " 'ቤ',\n",
       " '▁ለ',\n",
       " 'ሰራዊቱ',\n",
       " 'ና',\n",
       " '▁ለተ',\n",
       " 'ፈናቀሉ',\n",
       " '▁ወገኖች',\n",
       " '▁ድጋፍ',\n",
       " '▁ለማድረግ',\n",
       " '▁ሰ',\n",
       " 'መራ',\n",
       " '▁',\n",
       " 'ገቡ',\n",
       " '።',\n",
       " '▁ከንቲባ',\n",
       " '▁አዳነች',\n",
       " '▁አ',\n",
       " 'ቤ',\n",
       " 'ቤ',\n",
       " '▁ሰ',\n",
       " 'መራ',\n",
       " '▁',\n",
       " 'ሱ',\n",
       " 'ል',\n",
       " 'ጣ',\n",
       " 'ን',\n",
       " '▁አ',\n",
       " 'ሊ',\n",
       " 'ሚ',\n",
       " 'ራ',\n",
       " 'ህ',\n",
       " '▁አየር',\n",
       " '▁ማረፊያ',\n",
       " '▁ሲ',\n",
       " 'ደር',\n",
       " 'ሱ',\n",
       " '▁የአ',\n",
       " 'ፋ',\n",
       " 'ር',\n",
       " '▁ክልል',\n",
       " '▁ርእሰ',\n",
       " '▁መስተዳድር',\n",
       " '▁አቶ',\n",
       " '▁አ',\n",
       " 'ወ',\n",
       " 'ል',\n",
       " '▁አ',\n",
       " 'ር',\n",
       " 'ባ',\n",
       " 'ን',\n",
       " '▁ጨምሮ',\n",
       " '▁ከፍተኛ',\n",
       " '▁አመራሮች',\n",
       " 'ና',\n",
       " '▁የሀገር',\n",
       " '▁ሽማግሌዎች',\n",
       " '▁አቀባበል',\n",
       " '▁እንደ',\n",
       " 'ተደረገላቸው',\n",
       " '▁',\n",
       " 'ኢዜአ',\n",
       " '▁ዘግቧል።',\n",
       " '▁የ',\n",
       " 'ብ',\n",
       " 'ፁ',\n",
       " 'እ',\n",
       " '▁ወ',\n",
       " 'ቅዱስ',\n",
       " '▁አ',\n",
       " 'ቡ',\n",
       " 'ነ',\n",
       " '▁መ',\n",
       " 'ር',\n",
       " 'ቆ',\n",
       " 'ሬ',\n",
       " 'ዎ',\n",
       " 'ስ',\n",
       " '▁ሥር',\n",
       " 'ኣ',\n",
       " 'ተ',\n",
       " '▁ቀ',\n",
       " 'ብር',\n",
       " '▁ተ',\n",
       " 'ፈፀመ',\n",
       " '።',\n",
       " '▁የኢትዮጵያ',\n",
       " '▁',\n",
       " 'ኦርቶዶክስ',\n",
       " '▁ተ',\n",
       " 'ዋ',\n",
       " 'ሕ',\n",
       " 'ዶ',\n",
       " '▁ቤተ',\n",
       " '▁ክርስቲያን',\n",
       " '▁4',\n",
       " 'ኛው',\n",
       " '▁',\n",
       " 'ፓ',\n",
       " 'ት',\n",
       " 'ር',\n",
       " 'ያ',\n",
       " 'ር',\n",
       " 'ክ',\n",
       " '▁ብ',\n",
       " 'ፁ',\n",
       " 'እ',\n",
       " '▁ወ',\n",
       " 'ቅዱስ',\n",
       " '▁አ',\n",
       " 'ቡ',\n",
       " 'ነ',\n",
       " '▁መ',\n",
       " 'ር',\n",
       " 'ቆ',\n",
       " 'ሬ',\n",
       " 'ዎ',\n",
       " 'ስ',\n",
       " '▁ሥር',\n",
       " 'ኣ',\n",
       " 'ተ',\n",
       " '▁ቀ',\n",
       " 'ብር',\n",
       " '▁በዛሬው',\n",
       " '▁እለት',\n",
       " '▁(',\n",
       " 'መጋቢት',\n",
       " '▁4',\n",
       " '/',\n",
       " '2014',\n",
       " '▁ኣም',\n",
       " '▁',\n",
       " ')',\n",
       " '▁የ',\n",
       " 'ቤ',\n",
       " 'ተ',\n",
       " 'ክር',\n",
       " 'ስቲ',\n",
       " 'ያ',\n",
       " 'ኗ',\n",
       " '▁ሥር',\n",
       " 'ኣ',\n",
       " 'ተ',\n",
       " '▁ቀ',\n",
       " 'ኖ',\n",
       " 'ና',\n",
       " '▁በሚ',\n",
       " 'ያዘ',\n",
       " 'ው',\n",
       " '▁መልኩ',\n",
       " '▁በመ',\n",
       " 'ን',\n",
       " 'በረ',\n",
       " '▁',\n",
       " 'ፀ',\n",
       " 'ባ',\n",
       " 'ኦ',\n",
       " 'ት',\n",
       " '▁ቅ',\n",
       " 'ድ',\n",
       " 'ስት',\n",
       " '▁',\n",
       " 'ሥ',\n",
       " 'ላ',\n",
       " 'ሴ',\n",
       " '▁ካ',\n",
       " 'ቴ',\n",
       " 'ደራ',\n",
       " 'ል',\n",
       " '▁ተ',\n",
       " 'ፈ',\n",
       " 'ፅ',\n",
       " 'ሟ',\n",
       " 'ል።',\n",
       " '▁ጠቅላይ',\n",
       " '▁ሚኒስትር',\n",
       " '▁አቢይ',\n",
       " '▁አሕመድ',\n",
       " '▁እና',\n",
       " '▁',\n",
       " 'ል',\n",
       " 'ኡ',\n",
       " 'ካ',\n",
       " 'ቸው',\n",
       " '▁ለ',\n",
       " 'ስራ',\n",
       " '▁ጉብኝት',\n",
       " '▁ሱዳን',\n",
       " '▁ካ',\n",
       " 'ር',\n",
       " 'ቱ',\n",
       " 'ም',\n",
       " '▁ገብተዋል',\n",
       " '!',\n",
       " '▁ጠቅላይ',\n",
       " '▁ሚኒስትር',\n",
       " '▁አቢይ',\n",
       " '▁አሕመድ',\n",
       " '▁እና',\n",
       " '▁',\n",
       " 'ል',\n",
       " 'ኡ',\n",
       " 'ካ',\n",
       " 'ቸው',\n",
       " '▁ለአ',\n",
       " 'ን',\n",
       " 'ድ',\n",
       " '▁ቀን',\n",
       " '▁የስራ',\n",
       " '▁ጉብኝት',\n",
       " '▁ሱዳን',\n",
       " '▁ካ',\n",
       " 'ር',\n",
       " 'ቱ',\n",
       " 'ም',\n",
       " '▁ገብተዋል',\n",
       " '::',\n",
       " 'የ',\n",
       " 'ሱዳን',\n",
       " '▁',\n",
       " 'ሪ',\n",
       " 'ፐ',\n",
       " 'ብ',\n",
       " 'ሊ',\n",
       " 'ክ',\n",
       " '▁የ',\n",
       " 'ሽ',\n",
       " 'ግ',\n",
       " 'ግ',\n",
       " 'ር',\n",
       " '▁',\n",
       " 'ሉ',\n",
       " 'ኣ',\n",
       " 'ላዊ',\n",
       " 'ነት',\n",
       " '▁ምክር',\n",
       " '▁ቤት',\n",
       " '▁ፕሬዝዳንት',\n",
       " '▁ጄኔራል',\n",
       " '▁አብ',\n",
       " 'ደ',\n",
       " 'ል',\n",
       " '▁',\n",
       " 'ፈታ',\n",
       " 'ሕ',\n",
       " '▁አል',\n",
       " '▁',\n",
       " 'ቡ',\n",
       " 'ር',\n",
       " 'ሃ',\n",
       " 'ን',\n",
       " '▁አቀባበል',\n",
       " '▁አድርገው',\n",
       " 'ላ',\n",
       " 'ቸዋል',\n",
       " '::',\n",
       " '▁ወ',\n",
       " '/',\n",
       " 'ሮ',\n",
       " '▁',\n",
       " 'ሌ',\n",
       " 'ሊ',\n",
       " 'ሴ',\n",
       " '▁ደሳለኝ',\n",
       " '▁የፌዴራል',\n",
       " '▁ከፍተኛ',\n",
       " '▁ፍርድ',\n",
       " '▁ቤት',\n",
       " '▁',\n",
       " 'ፕሬ',\n",
       " 'ዜ',\n",
       " 'ዳ',\n",
       " 'ን',\n",
       " 'ት',\n",
       " '▁ሆነው',\n",
       " '▁ተ',\n",
       " 'ሾ',\n",
       " 'ሙ',\n",
       " '።',\n",
       " '▁ጠቅላይ',\n",
       " '▁ሚኒስትር',\n",
       " '▁ዶ',\n",
       " '/',\n",
       " 'ር',\n",
       " '▁አቢይ',\n",
       " '▁አህመድ',\n",
       " '▁ለ',\n",
       " 'ፌዴራ',\n",
       " 'ል',\n",
       " '▁ከፍተኛ',\n",
       " '▁ፍርድ',\n",
       " '▁ቤት',\n",
       " '▁በእ',\n",
       " 'ጩ',\n",
       " 'ነት',\n",
       " '▁ያ',\n",
       " 'ቀረ',\n",
       " 'ቧ',\n",
       " 'ቸው',\n",
       " '▁ወ',\n",
       " '/',\n",
       " 'ሮ',\n",
       " '▁',\n",
       " 'ሌ',\n",
       " 'ሊ',\n",
       " 'ሴ',\n",
       " '▁ደሳለኝ',\n",
       " '▁',\n",
       " 'ሹ',\n",
       " 'መ',\n",
       " 'ታቸው',\n",
       " '▁',\n",
       " 'ፀ',\n",
       " 'ድ',\n",
       " 'ቋል።',\n",
       " '▁የ',\n",
       " 'ህ',\n",
       " '/',\n",
       " 'ተ',\n",
       " '/',\n",
       " 'ም',\n",
       " '/',\n",
       " 'ቤት',\n",
       " '▁የፌዴራል',\n",
       " '▁ከፍተኛ',\n",
       " '▁ፍርድ',\n",
       " '▁ቤት',\n",
       " '▁',\n",
       " 'ሹ',\n",
       " 'መ',\n",
       " 'ት',\n",
       " 'ን',\n",
       " '▁በሁለት',\n",
       " '▁ድ',\n",
       " 'ም',\n",
       " 'ፀ',\n",
       " '▁ተ',\n",
       " 'አ',\n",
       " 'ቅ',\n",
       " 'ቦ',\n",
       " '▁በአ',\n",
       " 'ብ',\n",
       " 'ላ',\n",
       " 'ጫ',\n",
       " '▁ድምፅ',\n",
       " '▁ነው',\n",
       " '▁ያ',\n",
       " 'ፀደቀ',\n",
       " 'ው',\n",
       " '።',\n",
       " '▁አሳ',\n",
       " 'ሳ',\n",
       " 'ቢ',\n",
       " 'ው',\n",
       " '▁የ',\n",
       " 'ትራፊክ',\n",
       " '▁አደጋ',\n",
       " '▁በኢትዮጵያ',\n",
       " '▁በ',\n",
       " 'ቁ',\n",
       " 'ጥር',\n",
       " '▁አ',\n",
       " 'ሀ',\n",
       " 'ዝ',\n",
       " '⬇',\n",
       " '▁በኢትዮጵያ',\n",
       " '▁በ',\n",
       " '20',\n",
       " '10',\n",
       " '▁ኣም',\n",
       " '▁',\n",
       " '⊙',\n",
       " '▁',\n",
       " '40',\n",
       " 'ሺ',\n",
       " 'ህ',\n",
       " '▁9',\n",
       " '9',\n",
       " '8',\n",
       " '▁የተ',\n",
       " 'ሸ',\n",
       " 'ከርካሪ',\n",
       " '▁አደጋ',\n",
       " '▁ደርሷል',\n",
       " '፡',\n",
       " '▁',\n",
       " '⊙',\n",
       " '▁5',\n",
       " 'ሺ',\n",
       " 'ህ',\n",
       " '▁1',\n",
       " '18',\n",
       " '▁ሰዎች',\n",
       " '▁በተ',\n",
       " 'ሸ',\n",
       " 'ከርካሪ',\n",
       " '▁አደጋ',\n",
       " '▁ሳ',\n",
       " 'ቢያ',\n",
       " '▁ህይወታቸው',\n",
       " '▁አልፏል',\n",
       " '▁',\n",
       " '⊙',\n",
       " '▁7',\n",
       " 'ሺ',\n",
       " 'ህ',\n",
       " '▁7',\n",
       " '5',\n",
       " '4',\n",
       " '▁ሰዎች',\n",
       " '▁ከባድ',\n",
       " '▁የአ',\n",
       " 'ካ',\n",
       " 'ል',\n",
       " '▁ጉዳት',\n",
       " '▁ደርሶ',\n",
       " 'ባቸዋል',\n",
       " '▁',\n",
       " '⊙',\n",
       " '▁7',\n",
       " 'ሺ',\n",
       " 'ህ',\n",
       " '▁7',\n",
       " '7',\n",
       " '5',\n",
       " '▁ሰዎች',\n",
       " '▁ቀ',\n",
       " 'ላል',\n",
       " '▁የአ',\n",
       " 'ካ',\n",
       " 'ል',\n",
       " '▁ጉዳት',\n",
       " '▁ደርሶ',\n",
       " 'ባቸዋል',\n",
       " '▁©',\n",
       " 'EBC',\n",
       " '▁የአ',\n",
       " 'ዲ',\n",
       " 'ሰ',\n",
       " '▁አበባ',\n",
       " '▁ፖሊስ',\n",
       " '▁ኮሚሽን',\n",
       " '▁',\n",
       " 'ቁ',\n",
       " 'ጥ',\n",
       " 'ሩ',\n",
       " '▁በ',\n",
       " 'ው',\n",
       " 'ል',\n",
       " '▁ያል',\n",
       " 'ታወቀ',\n",
       " '▁የጦር',\n",
       " '▁መሳሪያ',\n",
       " '▁በ',\n",
       " 'ቁጥጥር',\n",
       " '▁ስር',\n",
       " '▁ማ',\n",
       " 'ዋሉ',\n",
       " 'ን',\n",
       " '▁ገለፀ',\n",
       " '።',\n",
       " '▁የአዲስ',\n",
       " '▁አበባ',\n",
       " '▁ፖሊስ',\n",
       " '▁ኮሚሽን',\n",
       " '▁',\n",
       " 'ቁ',\n",
       " 'ጥ',\n",
       " 'ሩ',\n",
       " '▁በ',\n",
       " 'ው',\n",
       " 'ል',\n",
       " '▁ያል',\n",
       " 'ታወቀ',\n",
       " '▁የጦር',\n",
       " '▁መሳሪያ',\n",
       " '▁በ',\n",
       " 'ቁጥጥር',\n",
       " '▁ስር',\n",
       " '▁አ',\n",
       " 'ው',\n",
       " 'ሏ',\n",
       " 'ል፡፡',\n",
       " '▁',\n",
       " 'ኮሚሽኑ',\n",
       " '▁በ',\n",
       " 'ቁጥጥር',\n",
       " '▁ስር',\n",
       " '▁ያ',\n",
       " 'ዋ',\n",
       " 'ለው',\n",
       " '▁የጦር',\n",
       " '▁መሳሪያ',\n",
       " '▁በመ',\n",
       " 'ዲ',\n",
       " 'ና',\n",
       " 'ዋ',\n",
       " '▁ውስጥ',\n",
       " '▁በ',\n",
       " 'ነ',\n",
       " 'ዳ',\n",
       " 'ጅ',\n",
       " '▁',\n",
       " 'ቦ',\n",
       " 'ቴ',\n",
       " '▁ሲ',\n",
       " 'ዘዋወ',\n",
       " 'ር',\n",
       " '▁የነበረ',\n",
       " '▁መሆኑ',\n",
       " '▁ተ',\n",
       " 'ገል',\n",
       " 'ጿ',\n",
       " 'ል',\n",
       " '▁መሆኑ',\n",
       " '፡፡',\n",
       " '▁©',\n",
       " 'ETV',\n",
       " '▁⬆️⬆️',\n",
       " 'የ',\n",
       " 'ቀድሞ',\n",
       " 'ው',\n",
       " '▁ኤ',\n",
       " 'ታ',\n",
       " 'ማ',\n",
       " 'ዦ',\n",
       " 'ር',\n",
       " '▁',\n",
       " 'ሹ',\n",
       " 'ም',\n",
       " '▁ሳ',\n",
       " 'ሞ',\n",
       " 'ራ',\n",
       " '▁የ',\n",
       " 'ኑ',\n",
       " 'ስ',\n",
       " '▁ከ',\n",
       " 'መከላከያ',\n",
       " '▁ሰራዊት',\n",
       " '▁በ',\n",
       " 'ጡ',\n",
       " 'ሮ',\n",
       " 'ታ',\n",
       " '▁ከተ',\n",
       " 'ሰ',\n",
       " 'ና',\n",
       " 'በ',\n",
       " 'ቱ',\n",
       " '▁በ',\n",
       " 'ህ',\n",
       " 'ላ',\n",
       " '▁ለ',\n",
       " 'መጀመሪያ',\n",
       " '▁ጊዜ',\n",
       " '▁',\n",
       " 'ዘ',\n",
       " 'ለ',\n",
       " 'ግ',\n",
       " '▁ያለ',\n",
       " '▁',\n",
       " 'ቃ',\n",
       " 'ለ',\n",
       " '▁',\n",
       " 'ም',\n",
       " 'ል',\n",
       " 'ል',\n",
       " 'ስ',\n",
       " '▁ከ',\n",
       " 'ድ',\n",
       " 'ም',\n",
       " 'ፂ',\n",
       " '▁ወ',\n",
       " 'ያ',\n",
       " 'ኔ',\n",
       " '▁ጋር',\n",
       " '▁አድርገዋል',\n",
       " '።',\n",
       " '▁በ',\n",
       " 'ሀገሪቱ',\n",
       " '▁ብዙ',\n",
       " '▁ነገር',\n",
       " '▁ቢ',\n",
       " 'ቀ',\n",
       " 'የ',\n",
       " 'ር',\n",
       " 'ም',\n",
       " '፣',\n",
       " '▁',\n",
       " 'ጡ',\n",
       " 'ሮ',\n",
       " 'ተኛ',\n",
       " 'ው',\n",
       " '▁',\n",
       " 'ጄ',\n",
       " 'ነ',\n",
       " 'ራ',\n",
       " 'ል',\n",
       " '▁ከ',\n",
       " 'ቀድሞ',\n",
       " '▁አ',\n",
       " 'መ',\n",
       " 'ለ',\n",
       " 'ካ',\n",
       " 'ከ',\n",
       " 'ታቸው',\n",
       " '▁ፈ',\n",
       " 'ቅ',\n",
       " '▁ያሉ',\n",
       " '▁አይ',\n",
       " 'መ',\n",
       " 'ስ',\n",
       " 'ሉ',\n",
       " 'ም',\n",
       " '።',\n",
       " '▁ሙሉ',\n",
       " 'ውን',\n",
       " '▁ያ',\n",
       " 'ድ',\n",
       " 'ም',\n",
       " 'ጡ',\n",
       " '▁',\n",
       " '⤵',\n",
       " '️',\n",
       " '▁ሀ',\n",
       " 'ይ',\n",
       " '▁ሰላም',\n",
       " '▁',\n",
       " 'የኔቲዩብ',\n",
       " '▁የ',\n",
       " 'ሀ',\n",
       " 'ረ',\n",
       " 'ር',\n",
       " '▁ከተማ',\n",
       " '▁የ',\n",
       " 'ደ',\n",
       " 'ረ',\n",
       " 'ቅ',\n",
       " '▁',\n",
       " 'ቁ',\n",
       " 'ሻ',\n",
       " 'ሻ',\n",
       " '▁አ',\n",
       " 'ወ',\n",
       " 'ጋ',\n",
       " 'ገድ',\n",
       " '▁ችግር',\n",
       " '▁አሁን',\n",
       " 'ም',\n",
       " '▁መፍትሄ',\n",
       " '▁አ',\n",
       " 'ላ',\n",
       " 'ገኘ',\n",
       " 'ም',\n",
       " '▁በዛሬው',\n",
       " '▁እለት',\n",
       " 'ም',\n",
       " '▁ከ',\n",
       " 'ከተማ',\n",
       " 'ው',\n",
       " '▁',\n",
       " 'ቆ',\n",
       " 'ሻ',\n",
       " 'ሻ',\n",
       " '▁',\n",
       " 'ጭ',\n",
       " 'ነው',\n",
       " '▁የ',\n",
       " 'ሄ',\n",
       " 'ዱ',\n",
       " '▁ሁለት',\n",
       " '▁የመ',\n",
       " 'ዘጋ',\n",
       " 'ጃ',\n",
       " '▁ቤት',\n",
       " '▁መ',\n",
       " 'ኪ',\n",
       " 'ኖች',\n",
       " '▁በ',\n",
       " 'አካባቢው',\n",
       " '▁ወጣቶች',\n",
       " '▁አ',\n",
       " 'ት',\n",
       " 'ደ',\n",
       " 'ፉ',\n",
       " 'ም',\n",
       " '▁ተ',\n",
       " 'ብ',\n",
       " 'ለው',\n",
       " '▁ዳ',\n",
       " 'ግ',\n",
       " 'ም',\n",
       " '▁የ',\n",
       " 'ያዙ',\n",
       " 'ት',\n",
       " 'ን',\n",
       " '▁',\n",
       " 'ቆ',\n",
       " 'ሻ',\n",
       " 'ሻ',\n",
       " '▁',\n",
       " 'ጭ',\n",
       " 'ነው',\n",
       " '▁ወደ',\n",
       " '▁ሀ',\n",
       " 'ረ',\n",
       " 'ር',\n",
       " '▁',\n",
       " '፡፡',\n",
       " '▁በአሁኑ',\n",
       " '▁ወቅት',\n",
       " 'ም',\n",
       " '▁በክልሉ',\n",
       " '▁',\n",
       " 'ፓ',\n",
       " 'ሊ',\n",
       " 'ስ',\n",
       " '▁ኮሚሽን',\n",
       " '▁',\n",
       " 'ፊ',\n",
       " 'ት',\n",
       " 'ለ',\n",
       " 'ፊ',\n",
       " 'ት',\n",
       " '▁',\n",
       " 'ቆ',\n",
       " 'መው',\n",
       " '▁ይገኛሉ',\n",
       " '፡፡',\n",
       " '▁ከ',\n",
       " 'ጂ',\n",
       " 'ግ',\n",
       " 'ጂ',\n",
       " 'ጋ',\n",
       " '▁ወደ',\n",
       " 'ሃ',\n",
       " 'ረ',\n",
       " 'ር',\n",
       " 'ና',\n",
       " '▁አዲስ',\n",
       " '▁አበባ',\n",
       " '▁የሚ',\n",
       " 'ወ',\n",
       " 'ስ',\n",
       " 'ደ',\n",
       " 'ው',\n",
       " '▁መንገድ',\n",
       " '▁ባ',\n",
       " 'ቢ',\n",
       " 'ሌ',\n",
       " '▁ላይ',\n",
       " '▁መንገዱ',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 96623\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of tokens\n",
    "number_of_tokens = len(tokens)\n",
    "\n",
    "# Print the number of tokens\n",
    "print(\"Number of tokens:\", number_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m303.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/abrham/.local/lib/python3.10/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/abrham/.local/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/abrham/.local/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/abrham/.local/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "  Downloading tokenizers-0.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m659.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/abrham/.local/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: requests in /home/abrham/.local/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/abrham/.local/lib/python3.10/site-packages (from transformers) (0.20.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/abrham/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/abrham/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/abrham/.local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Installing collected packages: safetensors, tokenizers, transformers\n",
      "Successfully installed safetensors-0.4.2 tokenizers-0.15.1 transformers-4.37.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m---> 13\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m eval_dataset \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     15\u001b[0m tokenized_train_dataset \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mmap(generate_and_tokenize_prompt)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "max_length = 512 # differs from datasets to datasets\n",
    "\n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    result = tokenizer(\n",
    "        formatting_func(prompt),\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "eval_dataset = dataset['test']\n",
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
